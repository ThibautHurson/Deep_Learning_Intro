{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_exercise4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK_zLrG3e1f_"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "from tensorflow import keras\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m_AUhp1k-XT",
        "outputId": "61ba6177-106c-4f9c-913e-7c26e59d1986"
      },
      "source": [
        "# Load data\n",
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url, untar=True, cache_dir='.', cache_subdir='')\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)\n",
        "seed = 123\n",
        "batch_size = 1024\n",
        "train_ds = tf.keras.preprocessing.text_dataset_from_directory('aclImdb/train', batch_size=batch_size, validation_split=0.2, subset='training', seed=seed)\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory('aclImdb/train', batch_size=batch_size, validation_split=0.2, subset='validation', seed=seed)\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 4s 0us/step\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClASvNYAl0vm"
      },
      "source": [
        "# Preprocessing\n",
        "# Create a custom standardization function to strip HTML break\n",
        "# tags ’<br />’.\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase,'<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation), ' ')\n",
        "# Vocabulary size and number of words in a sequence.\n",
        "vocab_size = 10000\n",
        "sequence_length = 100\n",
        "# Use the text vectorization layer to normalize, split, and map\n",
        "# strings to integers. Note that the layer uses the custom\n",
        "# standardization defined above.\n",
        "# Set maximum_sequence length as all samples are not of the same\n",
        "# length.\n",
        "vectorize_layer = TextVectorization(\n",
        "                              standardize=custom_standardization,\n",
        "                              max_tokens=vocab_size,\n",
        "                              output_mode='int',\n",
        "                              output_sequence_length=sequence_length)\n",
        "# Make a text-only dataset (no labels) and call adapt to build\n",
        "# the vocabulary.\n",
        "text_ds = train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Po0ZKrA5vrQw"
      },
      "source": [
        "embedding_dim = 16\n",
        "\n",
        "#Generate a model\n",
        "model = keras.Sequential([vectorize_layer,\n",
        "                          keras.layers.Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
        "                          keras.layers.GlobalAveragePooling1D(), # To deal with the fact that sentences do not have the same length\n",
        "                          keras.layers.Dense(16, activation='relu'),\n",
        "                          keras.layers.Dense(1, activation='sigmoid')])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0TBYsLFv99X"
      },
      "source": [
        "model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=['binary_accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QOeb-LLDyPOL",
        "outputId": "8e00a317-4a3e-4a72-cc06-f7a703db7ba8"
      },
      "source": [
        "model.fit(train_ds, batch_size=64, epochs=30, validation_data=val_ds)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "20/20 [==============================] - 3s 125ms/step - loss: 0.6917 - binary_accuracy: 0.5687 - val_loss: 0.6835 - val_binary_accuracy: 0.7100\n",
            "Epoch 2/40\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.6789 - binary_accuracy: 0.7250 - val_loss: 0.6631 - val_binary_accuracy: 0.7288\n",
            "Epoch 3/40\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 0.6544 - binary_accuracy: 0.7428 - val_loss: 0.6310 - val_binary_accuracy: 0.7508\n",
            "Epoch 4/40\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.6158 - binary_accuracy: 0.7710 - val_loss: 0.5874 - val_binary_accuracy: 0.7682\n",
            "Epoch 5/40\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.5645 - binary_accuracy: 0.7963 - val_loss: 0.5399 - val_binary_accuracy: 0.7862\n",
            "Epoch 6/40\n",
            "20/20 [==============================] - 2s 119ms/step - loss: 0.5090 - binary_accuracy: 0.8181 - val_loss: 0.4961 - val_binary_accuracy: 0.8016\n",
            "Epoch 7/40\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 0.4564 - binary_accuracy: 0.8346 - val_loss: 0.4610 - val_binary_accuracy: 0.8106\n",
            "Epoch 8/40\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 0.4119 - binary_accuracy: 0.8484 - val_loss: 0.4353 - val_binary_accuracy: 0.8196\n",
            "Epoch 9/40\n",
            "20/20 [==============================] - 2s 115ms/step - loss: 0.3762 - binary_accuracy: 0.8589 - val_loss: 0.4171 - val_binary_accuracy: 0.8230\n",
            "Epoch 10/40\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 0.3473 - binary_accuracy: 0.8695 - val_loss: 0.4044 - val_binary_accuracy: 0.8236\n",
            "Epoch 11/40\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 0.3236 - binary_accuracy: 0.8773 - val_loss: 0.3956 - val_binary_accuracy: 0.8266\n",
            "Epoch 12/40\n",
            "20/20 [==============================] - 2s 117ms/step - loss: 0.3035 - binary_accuracy: 0.8833 - val_loss: 0.3897 - val_binary_accuracy: 0.8268\n",
            "Epoch 13/40\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.2863 - binary_accuracy: 0.8894 - val_loss: 0.3861 - val_binary_accuracy: 0.8266\n",
            "Epoch 14/40\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 0.2712 - binary_accuracy: 0.8959 - val_loss: 0.3844 - val_binary_accuracy: 0.8278\n",
            "Epoch 15/40\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.2578 - binary_accuracy: 0.9015 - val_loss: 0.3843 - val_binary_accuracy: 0.8280\n",
            "Epoch 16/40\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 0.2459 - binary_accuracy: 0.9061 - val_loss: 0.3853 - val_binary_accuracy: 0.8294\n",
            "Epoch 17/40\n",
            "20/20 [==============================] - 2s 115ms/step - loss: 0.2350 - binary_accuracy: 0.9097 - val_loss: 0.3872 - val_binary_accuracy: 0.8310\n",
            "Epoch 18/40\n",
            "20/20 [==============================] - 2s 115ms/step - loss: 0.2251 - binary_accuracy: 0.9145 - val_loss: 0.3900 - val_binary_accuracy: 0.8318\n",
            "Epoch 19/40\n",
            "20/20 [==============================] - 2s 117ms/step - loss: 0.2160 - binary_accuracy: 0.9196 - val_loss: 0.3935 - val_binary_accuracy: 0.8318\n",
            "Epoch 20/40\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.2076 - binary_accuracy: 0.9224 - val_loss: 0.3974 - val_binary_accuracy: 0.8312\n",
            "Epoch 21/40\n",
            "20/20 [==============================] - 2s 113ms/step - loss: 0.1997 - binary_accuracy: 0.9272 - val_loss: 0.4019 - val_binary_accuracy: 0.8304\n",
            "Epoch 22/40\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 0.1923 - binary_accuracy: 0.9311 - val_loss: 0.4067 - val_binary_accuracy: 0.8296\n",
            "Epoch 23/40\n",
            "20/20 [==============================] - 2s 114ms/step - loss: 0.1853 - binary_accuracy: 0.9337 - val_loss: 0.4118 - val_binary_accuracy: 0.8276\n",
            "Epoch 24/40\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.1787 - binary_accuracy: 0.9372 - val_loss: 0.4173 - val_binary_accuracy: 0.8272\n",
            "Epoch 25/40\n",
            "20/20 [==============================] - 2s 117ms/step - loss: 0.1724 - binary_accuracy: 0.9403 - val_loss: 0.4230 - val_binary_accuracy: 0.8258\n",
            "Epoch 26/40\n",
            "20/20 [==============================] - 2s 115ms/step - loss: 0.1663 - binary_accuracy: 0.9431 - val_loss: 0.4288 - val_binary_accuracy: 0.8252\n",
            "Epoch 27/40\n",
            "20/20 [==============================] - 2s 116ms/step - loss: 0.1606 - binary_accuracy: 0.9457 - val_loss: 0.4349 - val_binary_accuracy: 0.8242\n",
            "Epoch 28/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-be04f833b743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}